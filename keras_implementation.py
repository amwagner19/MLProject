import kerasfrom keras.models import Sequentialfrom keras.layers import Densefrom keras.wrappers.scikit_learn import KerasClassifierfrom keras.utils import np_utilsfrom sklearn.model_selection import cross_val_scorefrom sklearn.model_selection import KFoldfrom sklearn.preprocessing import LabelEncoderfrom sklearn.pipeline import Pipelineimport numpy as npimport pandas as pdimport sklearn.model_selectionimport sklearn.metricsfrom sklearn.linear_model import LogisticRegressionfrom sklearn.dummy import DummyClassifierimport mathimport itertoolsimport statsmodels.api as smfimport tensorflow as tffrom sklearn.model_selection import GridSearchCV   from sklearn.metrics import classification_reporttestAccuracyScores={}def calculateAccuracy(predicted, actuals):     if len(predicted)!=len(actuals):        return -1    else:         count=0        numRows=len(predicted)        for x in range(0,numRows):            if predicted[x]==actuals[x]:                count=count+1        accuracy=count/numRows        return accuracydef logisticRegression(trainFeatures,trainTarget):       model=LogisticRegression(multi_class="multinomial",random_state=1).fit(trainFeatures,trainTarget)    return modeldef separateFeaturesTarget(df):     features=df[['Number of speakers','Latitude','Longitude', 'Germany', 'Denmark', 'Netherlands', 'Poland', 'Belarus', 'Latvia', 'Lithuania', 'Russian Federation', 'Italy', 'Albania', 'Austria', 'Bosnia and Herzegovina', 'Bulgaria', 'Croatia', 'Estonia', 'Finland', 'France', 'Greece', 'Hungary', 'The former Yugoslav Republic of Macedonia', 'Romania', 'United Kingdom of Great Britain and Northern Ireland', 'Slovakia', 'Slovenia', 'Switzerland', 'Czech Republic', 'Turkey', 'Ukraine', 'Serbia', 'Belgium', 'India', 'Bolivia (Plurinational State of)', 'Chile', 'Azerbaijan', 'Myanmar', 'Bangladesh', 'Spain', 'Georgia', 'Iran (Islamic Republic of)', 'Pakistan', 'Colombia', 'Iraq', 'Israel', 'Jordan', 'Syrian Arab Republic', 'Armenia', 'China', 'Kyrgyzstan', 'Mongolia', 'Lebanon', 'Bhutan', 'Republic of Moldova', 'Oman', 'Kenya', 'Tajikistan', 'Lao People\'s Democratic Republic', 'Ireland', 'Kazakhstan', 'Argentina', 'Brazil', 'Norway', 'Guyana', 'Ethiopia', 'Uzbekistan', 'Central African Republic', 'Democratic Republic of the Congo', 'Micronesia (Federated States of)', 'Cameroon', 'Congo', 'Gabon', 'Ecuador', 'Canada', 'French Guiana (France)', 'Cambodia', 'Guinea-Bissau', 'Guinea', 'El Salvador', 'Liechtenstein', 'Egypt', 'Libyan Arab Jamahiriya', 'Palestine', 'Algeria', 'Morocco', 'Luxembourg', 'Sweden']].iloc[0:].values    target=df[['Degree of endangerment']].iloc[0:].values.ravel()    return features, targetdef cleanCountries(arr):    #aprint(arr['Countries'])    row=0    countriesDict={}    languageCountries=[]    count=0    for x in arr['Countries']:         x=str(x)        country=''        for y in range(0,len(x)):            if x[y]==',' or y==len(x):                country=country.strip()                if country not in countriesDict.keys():                    countriesDict[country]=count                    count=count+1                country=''            else:                 country+=x[y]         countryList=""    for x in countriesDict.keys():        arr[x]=[0]*len(arr['Countries'])        countryList=countryList+", '"+ str(x)+ "'"            for x in arr['Countries']:         x=str(x)        country=''        for y in range(0,len(x)):            if x[y]==',' or y==len(x):                country=country.strip()                arr[country][row]=1                country=''            else:                 country+=x[y]         row=row+1    return arr                    def cleanNumerics(arr):    arr[np.isnan(arr)] = np.median(arr[~np.isnan(arr)])    for x in range(0,len(arr)):        arr[x]=float(arr[x])    return arrdef cleanTarget(arr):    oneHotArr=[]    for x in range (0,len(arr)):         newArr=[0]*6        if arr[x]=='Vulnerable':            newArr[0]=1        elif arr[x]=='Severely endangered':            newArr[1]=1        elif arr[x]=='Definitely endangered':            newArr[2]=1        elif arr[x]=='Severely endangered':            newArr[3]=1        elif arr[x]=='Critically endangered':            newArr[4]=1        elif arr[x]=='Extinct':            newArr[5]=1        oneHotArr.append(newArr)                return oneHotArrdef cleanTarget2(arr):    for x in range (0,len(arr)):         if arr[x]=='Vulnerable':            arr[x]=0        elif arr[x]=='Severely endangered':            arr[x]=1        elif arr[x]=='Definitely endangered':            arr[x]=2        elif arr[x]=='Severely endangered':            arr[x]=3        elif arr[x]=='Critically endangered':            arr[x]=4        elif arr[x]=='Extinct':            arr[x]=5    return arrdef baseline_model():    model = Sequential()    model.add(Dense(88, activation='relu'))     model.add(Dense(5, activation='softmax'))     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])     return modeldef doGridSearch(model,parameters, features, target):    clf = GridSearchCV(model, parameters)    clf.fit(features, target)    return clf.best_params_def runModels(features, target, testF):        logModel=logisticRegression(features,target)        estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)    estimator.fit(features, target)        kerasPredict=estimator.predict(testF)    logPredict=logModel.predict(testF)        return kerasPredict, logPredict                    def readData():     extinctLanguages=pd.read_csv("extinctLanguages.csv",encoding= 'unicode_escape')    extinctLanguages=cleanCountries(extinctLanguages)    extinctLanguages['Number of speakers']=cleanNumerics(extinctLanguages['Number of speakers'])    extinctLanguages['Latitude']=cleanNumerics(extinctLanguages['Latitude'])    extinctLanguages['Longitude']=cleanNumerics(extinctLanguages['Longitude'])        extinctLanguageTrain, extinctLanguageValidation, extinctLanguageTest= np.split(extinctLanguages.sample(frac = 1, random_state = 42), [int(.7*len(extinctLanguages)), int(.85*len(extinctLanguages))])    extinctTrainFeatures, extinctTrainTarget=separateFeaturesTarget(extinctLanguageTrain)    extinctTestFeatures, extinctTestTarget=separateFeaturesTarget(extinctLanguageTest)    extinctValidationFeatures, extinctValidationTarget=separateFeaturesTarget(extinctLanguageValidation)            extinctTrainTarget=cleanTarget2(extinctTrainTarget)    extinctTestTarget=cleanTarget2(extinctTestTarget)    extinctValidationTarget=cleanTarget2(extinctValidationTarget)        extinctTrainFeatures = np.asarray(extinctTrainFeatures).astype('float32')    extinctTestFeatures = np.asarray(extinctTestFeatures).astype('float32')    extinctTrainTarget = np.asarray(extinctTrainTarget).astype('float32')    extinctTestTarget = np.asarray(extinctTestTarget).astype('float32')    extinctValidationFeatures= np.asarray(extinctValidationFeatures).astype('float32')    extinctValidationTarget= np.asarray(extinctValidationTarget).astype('float32')            kerasParameters={}    logParameters=[    {'classifier' : [LogisticRegression()],    'classifier__penalty' : ['l1', 'l2'],    'classifier__C' : np.logspace(-4, 4, 20),    'classifier__solver' : ['liblinear'],    'classifier__n_estimators' : list(range(10,101,10)),    'classifier__max_features' : list(range(6,32,5))}]        kerasBestFeatures=doGridSearch(KerasClassifier(build_fn=baseline_model), )    kerasValidationPrediction, logValidationPrediction=runModels(extinctTrainFeatures, extinctTrainTarget, extinctValidationFeatures)                            readData()    